{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00478428",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Go up to project root (from inside training/)\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '../..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81f4372d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import gc\n",
    "import random\n",
    "from core.models.hierarchical_transformer import HierarchicalTransformer\n",
    "from core.utils import create_transformer_dataset, TransformerLRScheduler\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import precision_recall_fscore_support\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad3d8136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean slate initialized!\n"
     ]
    }
   ],
   "source": [
    "def initial_cleanup():\n",
    "    # Memory cleanup\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.ipc_collect()\n",
    "    gc.collect()\n",
    "    \n",
    "    # Set random seeds\n",
    "    random.seed(69)\n",
    "    np.random.seed(69)\n",
    "    torch.manual_seed(69)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(69)\n",
    "        torch.cuda.manual_seed_all(69)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "    print(\"Clean slate initialized!\")\n",
    "\n",
    "# Call this at the top of your notebook\n",
    "initial_cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82da88f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using max_frames = 200 (95.0th percentile)\n",
      "Sequence length stats - Min: 0, Max: 404\n",
      "Filtering out sample with length 236\n",
      "Filtering out sample with length 236\n",
      "Filtering out sample with length 267\n",
      "Filtering out sample with length 267\n",
      "Filtering out sample with length 237\n",
      "Filtering out sample with length 237\n",
      "Filtering out sample with length 248\n",
      "Filtering out sample with length 248\n",
      "Filtering out sample with length 207\n",
      "Filtering out sample with length 207\n",
      "Filtering out sample with length 219\n",
      "Filtering out sample with length 219\n",
      "Filtering out sample with length 280\n",
      "Filtering out sample with length 280\n",
      "Filtering out sample with length 249\n",
      "Filtering out sample with length 249\n",
      "Filtering out sample with length 247\n",
      "Filtering out sample with length 247\n",
      "Filtering out sample with length 210\n",
      "Filtering out sample with length 210\n",
      "Filtering out sample with length 215\n",
      "Filtering out sample with length 215\n",
      "Filtering out sample with length 283\n",
      "Filtering out sample with length 283\n",
      "Filtering out sample with length 247\n",
      "Filtering out sample with length 247\n",
      "Filtering out sample with length 203\n",
      "Filtering out sample with length 203\n",
      "Filtering out sample with length 281\n",
      "Filtering out sample with length 281\n",
      "Filtering out sample with length 208\n",
      "Filtering out sample with length 208\n",
      "Filtering out sample with length 229\n",
      "Filtering out sample with length 229\n",
      "Filtering out sample with length 309\n",
      "Filtering out sample with length 309\n",
      "Filtering out sample with length 236\n",
      "Filtering out sample with length 236\n",
      "Filtering out sample with length 404\n",
      "Filtering out sample with length 404\n",
      "Filtering out sample with length 256\n",
      "Filtering out sample with length 256\n",
      "Filtering out sample with length 230\n",
      "Filtering out sample with length 230\n",
      "Filtering out sample with length 236\n",
      "Filtering out sample with length 236\n",
      "Filtering out sample with length 217\n",
      "Filtering out sample with length 217\n",
      "Filtering out sample with length 261\n",
      "Filtering out sample with length 261\n",
      "Filtering out sample with length 222\n",
      "Filtering out sample with length 315\n",
      "Filtering out sample with length 205\n",
      "Filtering out sample with length 216\n",
      "Filtering out sample with length 201\n",
      "Filtering out sample with length 238\n",
      "Filtering out sample with length 305\n",
      "Filtering out sample with length 263\n",
      "Filtering out sample with length 237\n",
      "Filtering out sample with length 212\n",
      "Filtering out sample with length 240\n",
      "Filtering out sample with length 331\n",
      "Filtering out sample with length 339\n",
      "Filtering out sample with length 309\n",
      "Filtering out sample with length 209\n",
      "Filtering out sample with length 207\n",
      "Filtering out sample with length 378\n",
      "Filtering out sample with length 342\n",
      "Filtering out sample with length 207\n",
      "Filtering out sample with length 221\n",
      "Filtering out sample with length 315\n",
      "Filtering out sample with length 263\n",
      "Filtering out sample with length 305\n",
      "Filtering out sample with length 205\n",
      "Filtering out sample with length 263\n",
      "Filtering out sample with length 212\n",
      "Filtering out sample with length 266\n",
      "Filtering out sample with length 331\n",
      "Filtering out sample with length 201\n",
      "Filtering out sample with length 240\n",
      "Filtering out sample with length 201\n",
      "Filtering out sample with length 205\n",
      "Filtering out sample with length 235\n",
      "Filtering out sample with length 262\n",
      "Filtering out sample with length 209\n",
      "Filtering out sample with length 221\n",
      "Filtering out sample with length 218\n",
      "Filtering out sample with length 339\n",
      "Filtering out sample with length 342\n",
      "Filtering out sample with length 309\n",
      "Filtering out sample with length 238\n",
      "Filtering out sample with length 266\n",
      "Filtering out sample with length 237\n",
      "Filtering out sample with length 216\n",
      "Filtering out sample with length 235\n",
      "Filtering out sample with length 262\n",
      "Filtering out sample with length 222\n",
      "Filtering out sample with length 249\n",
      "Filtering out sample with length 201\n",
      "Filtering out sample with length 205\n",
      "Filtering out sample with length 218\n",
      "Filtering out sample with length 249\n",
      "Filtering out sample with length 378\n",
      "Filtering out sample with length 263\n",
      "Filtering out sample with length 226\n",
      "Filtering out sample with length 226\n",
      "Filtering out sample with length 226\n",
      "Filtering out sample with length 226\n",
      "Filtering out sample with length 201\n",
      "Filtering out sample with length 201\n",
      "Filtering out sample with length 214\n",
      "Filtering out sample with length 214\n",
      "Kept 2112 out of 2224 samples\n",
      "Final dataset shape:\n",
      "X: (2112, 200, 33, 4)\n",
      "y: (2112,)\n",
      "attention_masks: (2112, 200)\n",
      "sequence_lengths: (2112,)\n",
      "Kept 2112 out of 2224 samples\n",
      "Number of samples filtered out due to length: 112\n"
     ]
    }
   ],
   "source": [
    "X_np, y_np, attention_masks_np, sequence_lengths_np = create_transformer_dataset(data_dir=\"../../data/keypoints\",verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9300bdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_np = X_np[:, :, :, :3]  # shape: (N, F, J, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90de3959",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce4aab0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = dict(\n",
    "    num_joints=33,\n",
    "    num_frames=201,\n",
    "    d_model=64,\n",
    "    nhead=2,\n",
    "    num_spatial_layers=1,\n",
    "    num_temporal_layers=1,\n",
    "    num_classes=3,\n",
    "    dim_feedforward=2048,\n",
    "    dropout=0.1\n",
    ")\n",
    "\n",
    "batch_size = 16\n",
    "epochs = 64\n",
    "k = 5  # K-Fold\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Prepare K-Fold Cross-Validation\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=69)\n",
    "\n",
    "fold_results = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0926dcc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Fold 1/5 ==========\n"
     ]
    }
   ],
   "source": [
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_np, y_np)):\n",
    "    print(f\"\\n========== Fold {fold+1}/{k} ==========\")\n",
    "\n",
    "    # Split the data\n",
    "    X_train_fold, X_val_fold = X_np[train_idx], X_np[val_idx]\n",
    "    y_train_fold, y_val_fold = y_np[train_idx], y_np[val_idx]\n",
    "    mask_train_fold, mask_val_fold = attention_masks_np[train_idx], attention_masks_np[val_idx]\n",
    "\n",
    "    # Convert to tensors\n",
    "    X_train_tensor = torch.from_numpy(X_train_fold).float()\n",
    "    y_train_tensor = torch.from_numpy(y_train_fold).long()\n",
    "    mask_train_tensor = torch.from_numpy(mask_train_fold).float()\n",
    "\n",
    "    X_val_tensor = torch.from_numpy(X_val_fold).float()\n",
    "    y_val_tensor = torch.from_numpy(y_val_fold).long()\n",
    "    mask_val_tensor = torch.from_numpy(mask_val_fold).float()\n",
    "\n",
    "    # Create datasets and loaders\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor, mask_train_tensor)\n",
    "    val_dataset = TensorDataset(X_val_tensor, y_val_tensor, mask_val_tensor)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "    # Initialize model and training components\n",
    "    model = HierarchicalTransformer(**parameters).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.05)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=5e-3, betas=(0.9, 0.98), eps=1e-9, weight_decay=1e-4)\n",
    "    num_steps_per_epoch = len(train_loader)\n",
    "    warmup_steps = int(0.1 * num_steps_per_epoch * epochs)\n",
    "    scheduler = TransformerLRScheduler(optimizer, d_model=parameters['d_model'], warmup_steps=warmup_steps)\n",
    "\n",
    "    # Tracking metrics\n",
    "    best_val_loss = float('inf')\n",
    "    patience = 5\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    val_loss_history = []\n",
    "    val_acc_history = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        correct = 0\n",
    "\n",
    "        for X_batch, y_batch, mask_batch in train_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            mask_batch = mask_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x=X_batch, temporal_mask=mask_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            train_loss += loss.item() * X_batch.size(0)\n",
    "            correct += (outputs.argmax(1) == y_batch).sum().item()\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_acc = correct / len(train_loader.dataset)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch, mask_batch in val_loader:\n",
    "                X_batch = X_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                mask_batch = mask_batch.to(device)\n",
    "\n",
    "                outputs = model(x=X_batch, temporal_mask=mask_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "\n",
    "                val_loss += loss.item() * X_batch.size(0)\n",
    "                preds = outputs.argmax(1)\n",
    "                val_correct += (preds == y_batch).sum().item()\n",
    "\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(y_batch.cpu().numpy())\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_acc = val_correct / len(val_loader.dataset)\n",
    "\n",
    "        val_loss_history.append(val_loss)\n",
    "        val_acc_history.append(val_acc)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f} | \"\n",
    "              f\"Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f}\")\n",
    "\n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch+1}.\")\n",
    "            break\n",
    "\n",
    "    # Compute precision, recall, and f1 score for this fold\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        all_labels, all_preds, average='macro', zero_division=0\n",
    "    )\n",
    "\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "    fold_results.append({\n",
    "        'val_acc': val_acc_history[-1],\n",
    "        'val_loss': val_loss_history[-1],\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    })\n",
    "\n",
    "# --- Final Summary ---\n",
    "val_accs = [res['val_acc'] for res in fold_results]\n",
    "val_losses = [res['val_loss'] for res in fold_results]\n",
    "\n",
    "print(\"\\n========== K-Fold Cross-Validation Summary ==========\")\n",
    "print(f\"Average Validation Accuracy: {np.mean(val_accs):.4f} ± {np.std(val_accs):.4f}\")\n",
    "print(f\"Average Validation Loss:     {np.mean(val_losses):.4f} ± {np.std(val_losses):.4f}\")\n",
    "print(f\"Average Precision:           {np.mean(precision_scores):.4f} ± {np.std(precision_scores):.4f}\")\n",
    "print(f\"Average Recall:              {np.mean(recall_scores):.4f} ± {np.std(recall_scores):.4f}\")\n",
    "print(f\"Average F1 Score:            {np.mean(f1_scores):.4f} ± {np.std(f1_scores):.4f}\")\n",
    "print(\"=====================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec825482",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
