{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "216fd3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Go up to project root (from inside training/)\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '../..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90d184df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.models.hierarchical_transformer import HierarchicalTransformer\n",
    "from core.models.base_transformer_model import SimpleTransformerEncoder as StandardTransformer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd137268",
   "metadata": {},
   "outputs": [],
   "source": [
    "htformer_weights = \"../../models/final/hierarchical_transformer_f201_d64_h2_s1_t1_do0.1_20250701_2251.pth\"\n",
    "stformer_weights = \"../../models/final/base_hierarchical_transformer_f201_d64_h2_do0.1_20250702_0105.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f6e7a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "736ff8cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "htformer = HierarchicalTransformer(\n",
    "    num_classes=3,\n",
    "    num_frames=201,\n",
    "    d_model=64,\n",
    "    nhead=2,\n",
    "    dim_feedforward=2048,\n",
    "    dropout=0.1,\n",
    "    num_joints=33,\n",
    "    num_spatial_layers=1,\n",
    "    num_temporal_layers=1\n",
    ").to(device)\n",
    "\n",
    "htformer.load_state_dict(torch.load(htformer_weights, map_location=device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9766f710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "562755\n"
     ]
    }
   ],
   "source": [
    "# print parameters\n",
    "print(sum(p.numel() for p in htformer.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0db84d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stformer = StandardTransformer(\n",
    "    num_classes=3,\n",
    "    num_frames=201,\n",
    "    d_model=64,\n",
    "    nhead=2,\n",
    "    dim_feedforward=2048,\n",
    "    dropout=0.1,\n",
    "    num_joints=33,\n",
    "    num_layers=2,\n",
    ").to(device)\n",
    "\n",
    "stformer.load_state_dict(torch.load(stformer_weights, map_location=device))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42aa57da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "562755\n"
     ]
    }
   ],
   "source": [
    "# print parameters\n",
    "print(sum(p.numel() for p in stformer.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19ee2c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding.weight: 192 parameters\n",
      "embedding.bias: 64 parameters\n",
      "spatial_encoder.transformer.layers.0.self_attn.in_proj_weight: 12288 parameters\n",
      "spatial_encoder.transformer.layers.0.self_attn.in_proj_bias: 192 parameters\n",
      "spatial_encoder.transformer.layers.0.self_attn.out_proj.weight: 4096 parameters\n",
      "spatial_encoder.transformer.layers.0.self_attn.out_proj.bias: 64 parameters\n",
      "spatial_encoder.transformer.layers.0.linear1.weight: 131072 parameters\n",
      "spatial_encoder.transformer.layers.0.linear1.bias: 2048 parameters\n",
      "spatial_encoder.transformer.layers.0.linear2.weight: 131072 parameters\n",
      "spatial_encoder.transformer.layers.0.linear2.bias: 64 parameters\n",
      "spatial_encoder.transformer.layers.0.norm1.weight: 64 parameters\n",
      "spatial_encoder.transformer.layers.0.norm1.bias: 64 parameters\n",
      "spatial_encoder.transformer.layers.0.norm2.weight: 64 parameters\n",
      "spatial_encoder.transformer.layers.0.norm2.bias: 64 parameters\n",
      "temporal_encoder.transformer.layers.0.self_attn.in_proj_weight: 12288 parameters\n",
      "temporal_encoder.transformer.layers.0.self_attn.in_proj_bias: 192 parameters\n",
      "temporal_encoder.transformer.layers.0.self_attn.out_proj.weight: 4096 parameters\n",
      "temporal_encoder.transformer.layers.0.self_attn.out_proj.bias: 64 parameters\n",
      "temporal_encoder.transformer.layers.0.linear1.weight: 131072 parameters\n",
      "temporal_encoder.transformer.layers.0.linear1.bias: 2048 parameters\n",
      "temporal_encoder.transformer.layers.0.linear2.weight: 131072 parameters\n",
      "temporal_encoder.transformer.layers.0.linear2.bias: 64 parameters\n",
      "temporal_encoder.transformer.layers.0.norm1.weight: 64 parameters\n",
      "temporal_encoder.transformer.layers.0.norm1.bias: 64 parameters\n",
      "temporal_encoder.transformer.layers.0.norm2.weight: 64 parameters\n",
      "temporal_encoder.transformer.layers.0.norm2.bias: 64 parameters\n",
      "classifier.weight: 192 parameters\n",
      "classifier.bias: 3 parameters\n"
     ]
    }
   ],
   "source": [
    "for name, param in htformer.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"{name}: {param.numel()} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30eab9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding.weight: 192 parameters\n",
      "embedding.bias: 64 parameters\n",
      "transformer.layers.0.self_attn.in_proj_weight: 12288 parameters\n",
      "transformer.layers.0.self_attn.in_proj_bias: 192 parameters\n",
      "transformer.layers.0.self_attn.out_proj.weight: 4096 parameters\n",
      "transformer.layers.0.self_attn.out_proj.bias: 64 parameters\n",
      "transformer.layers.0.linear1.weight: 131072 parameters\n",
      "transformer.layers.0.linear1.bias: 2048 parameters\n",
      "transformer.layers.0.linear2.weight: 131072 parameters\n",
      "transformer.layers.0.linear2.bias: 64 parameters\n",
      "transformer.layers.0.norm1.weight: 64 parameters\n",
      "transformer.layers.0.norm1.bias: 64 parameters\n",
      "transformer.layers.0.norm2.weight: 64 parameters\n",
      "transformer.layers.0.norm2.bias: 64 parameters\n",
      "transformer.layers.1.self_attn.in_proj_weight: 12288 parameters\n",
      "transformer.layers.1.self_attn.in_proj_bias: 192 parameters\n",
      "transformer.layers.1.self_attn.out_proj.weight: 4096 parameters\n",
      "transformer.layers.1.self_attn.out_proj.bias: 64 parameters\n",
      "transformer.layers.1.linear1.weight: 131072 parameters\n",
      "transformer.layers.1.linear1.bias: 2048 parameters\n",
      "transformer.layers.1.linear2.weight: 131072 parameters\n",
      "transformer.layers.1.linear2.bias: 64 parameters\n",
      "transformer.layers.1.norm1.weight: 64 parameters\n",
      "transformer.layers.1.norm1.bias: 64 parameters\n",
      "transformer.layers.1.norm2.weight: 64 parameters\n",
      "transformer.layers.1.norm2.bias: 64 parameters\n",
      "classifier.weight: 192 parameters\n",
      "classifier.bias: 3 parameters\n"
     ]
    }
   ],
   "source": [
    "for name, param in stformer.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"{name}: {param.numel()} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1df950",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
